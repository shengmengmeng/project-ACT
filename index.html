<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriately as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Enhancing Robustness in Learning with Noisy Labels: An Asymmetric Co-Training Approach">
  <meta property="og:title" content="Enhancing Robustness in Learning with Noisy Labels: An Asymmetric Co-Training Approach"/>
  <meta property="og:description" content="A novel asymmetric co-training approach to mitigate the negative impact induced by noisy labels."/>
  <meta property="og:url" content="https://arxiv.org/abs/2407.02778v1"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimensions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="Enhancing Robustness in Learning with Noisy Labels: An Asymmetric Co-Training Approach">
  <meta name="twitter:description" content="A novel asymmetric co-training approach to mitigate the negative impact induced by noisy labels.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimensions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Noisy labels, Asymmetric co-training, Sample selection">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Enhancing Robustness in Learning with Noisy Labels: An Asymmetric Co-Training Approach</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Enhancing Robustness in Learning with Noisy Labels: An Asymmetric Co-Training Approach</h1>
          <div class="is-size-5 publication-authors">
            <!-- Paper authors -->
            <span class="author-block">
              <a href="#" target="_blank">Mengmeng Sheng</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="#" target="_blank">Zeren Sun</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="#" target="_blank">Gensheng Pei</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="#" target="_blank">Tao Chen</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="#" target="_blank">Haonan Luo</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="#" target="_blank">Yazhou Yao</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup> Nanjing University of Science and Technology, <sup>2</sup> Southwest Jiaotong University<br>ACM International Conference on Multimedia (ACM MM), 2024</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Arxiv PDF link -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2407.02778v1.pdf" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>Paper</span>
              </a>
            </span>


          <!-- Github link -->
          <span class="link-block">
            <a href="https://github.com/NUST-Machine-Intelligence-Laboratory/ACT" target="_blank"
            class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
              <i class="fab fa-github"></i>
            </span>
            <span>Code</span>
          </a>
        </span>

        <!-- ArXiv abstract Link -->
        <span class="link-block">
          <a href="https://arxiv.org/abs/2407.02778v1" target="_blank"
          class="external-link button is-normal is-rounded is-dark">
          <span class="icon">
            <i class="ai ai-arxiv"></i>
          </span>
          <span>arXiv</span>
        </a>
      </span>
    </div>
  </div>
</div>
</div>
</div>
</section>




<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/Figure1.png" alt="Poster Dataset Distillation (PoDD)" class="center-image" style="max-width: 100%; height: auto;">
      <h2 class="subtitle has-text-centered">
        We propose a novel asymmetric co-training (<strong>ACT</strong>) approach to mitigate the negative impact induced by noisy labels. It trains two networks asymmetrically to improve the reliability of learned knowledge. Through this asymmetric training framework, our RTM and NTM can provide more distinctive insights for clean sample selection compared to existing SCT methods. We introduce two novel criteria to establish an asymmetric sample selection and mining strategy based on the relationship between model predictions, focusing on their consensus and disagreement with given labels. Moreover, we propose a dynamic sample re-weighting method, utilizing historical training states to enhance the reliability of our clean sample selection and mining.
      </h2>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Label noise, an inevitable issue in various real-world datasets, tends to impair the performance of deep neural networks. A large body of literature focuses on symmetric co-training, aiming to enhance model robustness by exploiting interactions between models with distinct capabilities. However, the symmetric training processes employed in existing methods often culminate in model consensus, diminishing their efficacy in handling noisy labels. To this end, we propose an <strong>A</strong>symmetric <strong>C</strong>o-<strong>T</strong>raining (<strong>ACT</strong>) method to mitigate the detrimental effects of label noise. Specifically, we introduce an asymmetric training framework in which one model (i.e., RTM) is robustly trained with a selected subset of clean samples while the other (i.e., NTM) is conventionally trained using the entire training set. We propose two novel criteria based on agreement and discrepancy between models, establishing asymmetric sample selection and mining. Moreover, a metric, derived from the divergence between models, is devised to quantify label memorization, guiding our method in determining the optimal stopping point for sample mining. Finally, we propose to dynamically re-weight identified clean samples according to their reliability inferred from historical information. We additionally employ consistency regularization to achieve further performance improvement. Extensive experimental results on synthetic and real-world datasets demonstrate the effectiveness and superiority of our method.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-4">Differences between Symmetric and Asymmetric Co-training Approachs</h2>

          <img src="static/images/Figure.png" alt="Self-Adaptive and Class-Balanced Sample Selection and Re-weighting" class="center-image">
          <div class="level-set has-text-justified">
            <p>
              SCT methods usually entail the simultaneous training of two networks with identical architectures but distinct weight initializatio. The twin networks adopt the same training strategy, capitalizing on their distinct learning capabilities to provide mutual guidance throughout the learning process. In our ACT approach, two models with identical architectures are simultaneously trained utilizing distinct training strategies.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-4">Average Test Accuracy on CIFAR100N and CIFAR80N Under Various Noise Conditions</h2>

          <img src="static/images/Table1.png" alt="Average Test Accuracy on CIFAR100N and CIFAR80N Under Various Noise Conditions" class="center-image">
          <div class="level-set has-text-justified">
            <p>
              Experiments are conducted under symmetric and asymmetric label noise conditions. Results of existing methods are mainly drawn from previous works. † indicates methods re-implemented using their open-sourced code and default hyper-parameters.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-4">Comparison of Test Accuracy on Real-World Noisy Datasets</h2>

          <img src="static/images/Table2.png" alt="Comparison of Test Accuracy on Real-World Noisy Datasets" class="center-image">
          <div class="level-set has-text-justified">
            <p>
              The table shows the experimental results of existing methods and ACT on Web-Aircraft, Web-Bird, and Web-Car datasets. Results of existing methods are mainly drawn from previous works. † indicates methods re-implemented using their open-sourced code and default hyper-parameters.            </p>
          </div>
          
          <img src="static/images/Table3.png" alt="Comparison of Test Accuracy on Real-World Noisy Datasets" class="center-image">
          <div class="level-set has-text-justified">
            <p>
              The table shows the experimental results of existing methods and ACT on Food-101N.</p>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</section>







<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{sheng2024foster,
  title={Enhancing Robustness in Learning with Noisy Labels: An Asymmetric Co-Training Approach},
  author={Sheng, Mengmeng and Sun, Zeren and Gensheng, Pei and Chen, Tao and Haonan, Luo and Yao, Yazhou},
  journal={ACM International Conference on Multimedia (ACM MM)},
  year={2024}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->



<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>
</html>
